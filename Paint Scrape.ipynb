{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1581258a",
   "metadata": {},
   "source": [
    "## Paint Scrape Project\n",
    "\n",
    "Start by importing the necessary libraries:\n",
    "Download the ones you don't have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d003ab4-c7b3-4a95-9c52-1828ce5b5545",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0778553e",
   "metadata": {},
   "source": [
    "### Sherwin Williams\n",
    "\n",
    "We get this code generated for us by Insomnia: \n",
    "https://www.youtube.com/watch?v=DqtlR0y0suo\n",
    "\n",
    "We start by getting the categories for Sherwin Williams' paint, but this isn't very useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a026b0e-b931-4745-b50b-403b0967dca9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://api.sherwin-williams.com/prism/v1/colors/sherwin\"\n",
    "\n",
    "querystring = {\"lng\":\"en-US\",\"_corev\":\"5.1.0\"}\n",
    "\n",
    "payload = \"\"\n",
    "headers = {\n",
    "    ## INSERT YOUR HEADERS\n",
    "    }\n",
    "\n",
    "response = requests.request(\"GET\", url, data=payload, headers=headers, params=querystring)\n",
    "\n",
    "r = response.json()\n",
    "df = pd.json_normalize(r)\n",
    "df.to_csv('sherwin_paint.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd74c3e",
   "metadata": {
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "031a1b09-8966-4207-b269-c911f99f4da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://api.sherwin-williams.com/prism/v1/chunks/sherwin\"\n",
    "\n",
    "querystring = {\"lng\":\"en-US\",\"_corev\":\"5.1.0\"}\n",
    "\n",
    "payload = \"\"\n",
    "headers = {\n",
    "    ## INSERT YOUR HEADERS\n",
    "}\n",
    "\n",
    "response = requests.request(\"GET\", url, data=payload, headers=headers, params=querystring)\n",
    "\n",
    "r = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71ae57cf-f773-4eaf-817a-48150b3b3211",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "names_df = pd.json_normalize(r['names'])\n",
    "\n",
    "names = []\n",
    "for category in names_df:\n",
    "    group_number = 1\n",
    "    for color_name in r['names'][category]:\n",
    "        names.append((category,color_name, group_number))\n",
    "        group_number += 1\n",
    "        \n",
    "\n",
    "categories = pd.DataFrame(names, columns=['Category', 'Name', 'Group'])\n",
    "categories.drop_duplicates(inplace=True)\n",
    "\n",
    "\n",
    "values_df = pd.json_normalize(r['values'])\n",
    "\n",
    "# keep only categories that appear in the values\n",
    "categoriesToKeep = list(values_df.columns)\n",
    "categories = categories[categories['Category'].isin(categoriesToKeep)]\n",
    "categories.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "values = []\n",
    "for category in values_df:\n",
    "    name_groups = []\n",
    "    group_number = 1\n",
    "    for name_group in r['values'][category]:\n",
    "        for value in name_group:\n",
    "            values.append((category, value, group_number))\n",
    "        group_number += 1\n",
    "values_df = pd.DataFrame(values, columns=['Category', 'Value', 'Group'])\n",
    "\n",
    "\n",
    "merged_df = pd.merge(values_df, categories, on=['Category', 'Group'])\n",
    "merged_df.to_csv('sherwin_paint_categories.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e0de50",
   "metadata": {},
   "source": [
    "### Benjamin Moore\n",
    "\n",
    "Again, using Insomnia for this cURL get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a2e624-93e0-472d-8161-67619ae141b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = \"https://www.benjaminmoore.com/en-us/paint-colors\"\n",
    "\n",
    "payload = \"\"\n",
    "headers = {\n",
    "    ## INSERT YOUR HEADERS\n",
    "}\n",
    "\n",
    "response = requests.request(\"GET\", url, data=payload, headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45fee98",
   "metadata": {},
   "source": [
    "Import the following libraries to easily parse the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d1cb39-65c1-4b64-85aa-95556dffeccd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d87c83-7139-4c6b-89ee-cb468855715a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Opening the html file \n",
    "HTMLFile = open(\"benjamin.html\", \"r\") \n",
    "\n",
    "soup = BeautifulSoup(HTMLFile, 'html.parser')\n",
    "\n",
    "# Find the script tag containing __NEXT_DATA__\n",
    "script_tag = soup.find('script', {'id':'__NEXT_DATA__'}).get_text()\n",
    "\n",
    "# load that data as json to parse\n",
    "jsondata = json.loads(script_tag)\n",
    "\n",
    "r = jsondata\n",
    "\n",
    "# Define the file path to save the JSON\n",
    "file_path = 'benny.json'  # Replace with your desired file path and name\n",
    "\n",
    "# Write the JSON object to a file with pretty formatting\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(jsondata, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1de017",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now we can parse the JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422dfdd1-22c3-4d00-b6d3-e75325177b11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use for categories\n",
    "categories = []\n",
    "for i in r['props']['pageProps']['componentData']['components']:\n",
    "    if i['color_data'] is not None:\n",
    "        for category in i['color_data']['data']:\n",
    "            category_name = category['name']\n",
    "            try:\n",
    "                color_infos = category['colors']  # Replace 'my_dict' and 'key' with your dictionary and key\n",
    "                for color in color_infos:\n",
    "                    tupledInfo = (category_name, color['name'],color['number'],color['hex'],color['r'],color['g'],\n",
    "                                  color['b'], color['description'], color['family'], color['url'], color['exterior_availability'],\n",
    "                                  color['lrv'], color['wetsample_sku'], color['drysample_sku'], color['estore_available'],\n",
    "                                  color['is_best_selling'], color['aliases'], color['product_types_available'],\n",
    "                                  color['stainOpacitiesAvailable'], color['indexNum'], color['harmony'],\n",
    "                                  color['similar'], color['equivalent'], color['palettes'], color['tags'], color['cdp_images'])\n",
    "                    categories.append(tupledInfo)\n",
    "\n",
    "            except KeyError:\n",
    "                tupledInfo = ('Off White Color Collection', category['name'],category['number'],category['hex'],category['r'],category['g'],\n",
    "                                  category['b'], category['description'], category['family'], category['url'], category['exterior_availability'],\n",
    "                                  category['lrv'], category['wetsample_sku'], category['drysample_sku'], category['estore_available'],\n",
    "                                  category['is_best_selling'], category['aliases'], category['product_types_available'],\n",
    "                                  category['stainOpacitiesAvailable'], 'NA', category['harmony'],\n",
    "                                  category['similar'], category['equivalent'], category['palettes'], category['tags'], category['cdp_images'])\n",
    "                categories.append(tupledInfo)\n",
    "                \n",
    "                \n",
    "tupledInfo = (\n",
    "    'category_name', 'color_name', 'number', 'hex', 'r', 'g', 'b', 'description', 'family', 'url',\n",
    "    'exterior_availability', 'lrv', 'wetsample_sku', 'drysample_sku', 'estore_available',\n",
    "    'is_best_selling', 'aliases', 'product_types_available', 'stainOpacitiesAvailable',\n",
    "    'indexNum', 'harmony', 'similar', 'equivalent', 'palettes', 'tags', 'cdp_images'\n",
    ")\n",
    "\n",
    "# Extract variable names into a list\n",
    "variable_names = list(tupledInfo)\n",
    "\n",
    "\n",
    "results = pd.DataFrame(categories, columns=variable_names)\n",
    "\n",
    "results.to_csv('benjamin.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911d1e45",
   "metadata": {},
   "source": [
    "### Valspar\n",
    "\n",
    "For the valspar.html, I manually loaded the whole page to download the paint info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289a6971",
   "metadata": {},
   "outputs": [],
   "source": [
    "## valspar\n",
    "\n",
    "# Opening the html file of the Valspar url\n",
    "valspar_html = open(\"valspar.html\", \"r\") \n",
    "\n",
    "soup = BeautifulSoup(valspar_html, 'html.parser')\n",
    "\n",
    "# Find the div tag containing 'data-cbg-cmp-hook-wall' = 'wall-item'\n",
    "colors = soup.findAll('div', {'data-cbg-cmp-hook-wall':'wall-item'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e32dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data-color-collection, data-color-family, data-color-id, data-color-name, data-hex, data-lrv, data-sort, href,\n",
    "results = []\n",
    "for color in colors:\n",
    "    color_id = color.get('data-color-id')\n",
    "    color_name = color.get('data-color-name')\n",
    "    color_category = color.get('data-color-family')\n",
    "    color_collection = color.get('data-color-collection')\n",
    "    color_hex = color.get('data-hex')\n",
    "    color_lrv = color.get('data-lrv')\n",
    "    color_link = 'valspar.com/'+color.find('a').get('href')\n",
    "    \n",
    "    resultTuple = (color_id, color_name, color_category, color_collection, color_hex, color_lrv, color_link)\n",
    "    results.append(resultTuple)\n",
    "\n",
    "# convert list of tuples into pd\n",
    "columnNames = ['id', 'name', 'category', 'collection', 'hex', 'lrv', 'link']\n",
    "valspar = pd.DataFrame(results, columns=columnNames)\n",
    "\n",
    "# save output\n",
    "valspar.to_csv('valspar.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9e17e3",
   "metadata": {},
   "source": [
    "### Behr\n",
    "\n",
    "For we need to use a Chrome driver to load the JavaScript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd91dd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "from time import sleep\n",
    "\n",
    "#https://github.com/ultrafunkamsterdam/undetected-chromedriver\n",
    "import undetected_chromedriver as uc\n",
    "driver = uc.Chrome(headless=True, use_subprocess=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d8707a",
   "metadata": {},
   "source": [
    "We also need to use a YAML extractor, which is made easy through the Chomre extension selectorlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e91875a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selectorlib import Extractor\n",
    "\n",
    "# Create an Extractor by reading from the YAML file\n",
    "e = Extractor.from_yaml_file('Behr.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b49aed",
   "metadata": {},
   "source": [
    "Now we can similarly use Insomnia to make a request to get all the colors that Behr has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91c00655",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.behr.com/omsproductservice/services/getAllAvailableColorIds\"\n",
    "\n",
    "querystring = {\"prodcode\":\"cf\",\"surface\":\"\"}\n",
    "\n",
    "payload = \"\"\n",
    "headers = {\n",
    "    ## insert header\n",
    "}\n",
    "\n",
    "response = requests.request(\"GET\", url, data=payload, headers=headers, params=querystring)\n",
    "\n",
    "r = response.json()\n",
    "\n",
    "allUrls = []\n",
    "for i in r:\n",
    "    currentURL = 'https://www.behr.com/consumer/ColorDetailView/' + i\n",
    "    allUrls.append(currentURL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ec8190",
   "metadata": {},
   "source": [
    "Go through all the urls for the product and save the content to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d3828af",
   "metadata": {},
   "outputs": [],
   "source": [
    "allResults = []\n",
    "driver = uc.Chrome(headless=True, use_subprocess=False)\n",
    "x = 1\n",
    "\n",
    "for url in allUrls:\n",
    "    driver.get(url)\n",
    "    sleep(2)\n",
    "    html_content = driver.page_source\n",
    "    data = e.extract(html_content)\n",
    "    allResults.append(data)\n",
    "    x +=1\n",
    "driver.close()\n",
    "\n",
    "# using these column names create a pandas datagrame\n",
    "columnNames = ['Name', 'mfg_num', 'lrv', 'rgb', 'category', 'hexcode']\n",
    "results = pd.DataFrame(allResults, columns=columnNames)\n",
    "\n",
    "\n",
    "results.to_csv('behr.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
